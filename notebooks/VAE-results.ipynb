{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a20396e",
   "metadata": {},
   "source": [
    "# In this notebook\n",
    "This notebook handles validating the results of the VAE to ensure that the reconstruction *generally* looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024fa437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import joblib\n",
    "sys.path.append(\"../scripts/\")\n",
    "import vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f9531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../scripts/model/model_3epoch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c35d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = joblib.load('../data/san_francisco/cached/count_vec.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19eea829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scripts/vae.py:62: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  tweets = self._load_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached file was found...loading lemmatized tweets from the cache.\n",
      "Creating the count vector\n"
     ]
    }
   ],
   "source": [
    "tweets = vae.Tweets('../data/san_francisco/')\n",
    "x_test = tweets.load(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6584e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vae.VAE(tweets.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da9e3b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../scripts/model/model_3epoch.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "118eb101",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_doc = x_test[0] \n",
    "recon = model(test_doc)\n",
    "s, W, mu, logvar = recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7e6aeb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = s @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f11cc7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_params = recon/recon.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "163e61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_vals = mult_params.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "190f65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa569a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cough :  True\n",
      "lung :  True\n",
      "eye :  True\n",
      "itch :  True\n",
      "fire :  False\n",
      "wildfire :  True\n",
      "smoke :  True\n",
      "hurt :  True\n"
     ]
    }
   ],
   "source": [
    "# Make sure sensible words are in our corpus\n",
    "words_to_check = [\n",
    "    'cough',\n",
    "    'lung',\n",
    "    'eye',\n",
    "    'itch',\n",
    "    'fire',\n",
    "    'wildfire',\n",
    "    'smoke',\n",
    "    'hurt'\n",
    "]\n",
    "\n",
    "for w in words_to_check:\n",
    "    \n",
    "    print(w, ': ', w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4da0f913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mexican\n",
      "keeper\n",
      "jeopardy\n",
      "attack\n",
      "florida\n",
      "spanish\n",
      "dem\n",
      "cater\n",
      "mullen\n",
      "tip\n",
      "mute\n",
      "dreamforce\n",
      "sacrifice\n",
      "max\n",
      "hacker\n",
      "hitter\n",
      "specific\n",
      "lego\n",
      "module\n",
      "sibling\n",
      "contrary\n",
      "transportation\n"
     ]
    }
   ],
   "source": [
    "# What are the most probable words in this reconstruction?\n",
    "for i, v in enumerate(reversed(np.argsort(recon_vals))):\n",
    "    print(words[v])\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "abea1833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just\n",
      "good\n",
      "know\n",
      "like\n",
      "thank\n",
      "love\n",
      "make\n",
      "people\n",
      "game\n",
      "want\n",
      "say\n",
      "right\n",
      "great\n",
      "look\n",
      "today\n",
      "way\n",
      "think\n",
      "hit\n",
      "don\n",
      "work\n",
      "time\n",
      "day\n"
     ]
    }
   ],
   "source": [
    "# What are the most probable words in our generated document?\n",
    "for i, v in enumerate(reversed(np.argsort(test_doc))):\n",
    "    print(words[v])\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cd194baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japanese\n",
      "appt\n",
      "francis\n",
      "doom\n",
      "oil\n",
      "cowardly\n",
      "misogynistic\n",
      "patent\n",
      "employment\n",
      "dough\n",
      "fraud\n",
      "fit\n",
      "outing\n",
      "outfit\n",
      "wood\n",
      "quite\n",
      "omarosa\n",
      "hahaha\n",
      "rewatch\n",
      "title\n",
      "prob\n",
      "surgeon\n"
     ]
    }
   ],
   "source": [
    "# Least probable words in the reconstruction\n",
    "for i, v in enumerate(np.argsort(recon_vals)):\n",
    "    print(words[v])\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a40e96e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa\n",
      "organic\n",
      "organ\n",
      "org\n",
      "oreo\n",
      "oregon\n",
      "ordinary\n",
      "orbit\n",
      "oracle\n",
      "optional\n",
      "optimize\n",
      "optimistic\n",
      "optimism\n",
      "opt\n",
      "oppression\n",
      "oppress\n",
      "opposition\n",
      "oppose\n",
      "opportunity\n",
      "opponent\n",
      "opioid\n",
      "opinion\n"
     ]
    }
   ],
   "source": [
    "# What are the lest probable words in our generated document?\n",
    "for i, v in enumerate(np.argsort(test_doc)):\n",
    "    print(words[v])\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0a8d3a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  0.0005555555555555556\n",
      "Max:  0.1\n"
     ]
    }
   ],
   "source": [
    "# Min probability of a word being in this corpus with min_df=100\n",
    "print(\"Min: \", 1000/(1.8*10**6))\n",
    "\n",
    "# Max prob of a word being in this corpus with max_df=0.1\n",
    "print(\"Max: \", 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cc530103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-15.7212, -34.9691, -36.0413, -35.4208, -30.5385, -33.4864, -35.0444,\n",
       "         -33.2605, -37.6280, -35.3061, -32.4391, -37.4034, -37.1712, -30.5614,\n",
       "         -37.9732, -32.9141, -35.1267, -34.4124, -35.7661,   0.3856]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ae7cdbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2437e-06, 2.2084e-14, 3.6074e-16, 3.9704e-15, 1.1269e-12, 9.9991e-15,\n",
       "         7.4339e-16, 2.9564e-15, 3.2217e-14, 1.4587e-15, 2.1465e-15, 1.1409e-14,\n",
       "         3.5717e-15, 4.5019e-15, 7.6575e-15, 2.9934e-14, 3.7548e-16, 1.6810e-15,\n",
       "         3.8571e-15, 2.8558e-14]], grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(logvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763f835",
   "metadata": {},
   "source": [
    "## Conclusion: \n",
    "\n",
    "Looks like this specific model is probably doing OK, but some words are perhaps too infrequent or too frequent.\n",
    "\n",
    "We should look at words that only appear in at least every 20 or 50 tweets, but not more than 1000, so that they have a probability of showing up enough, but not too much.\n",
    "\n",
    "Also, it looks like we are getting negative mu's with small variances. This doesn't make sense. We need to constrain our mus to be positive, with small variances.\n",
    "\n",
    "TODO:\n",
    " - [ ] Change the count vector parameters.\n",
    " - [ ] Review the KL divergence...shouldn't these MUs be positive?\n",
    " - [ ] Add more components to the topic matrix. 20 seems too small...how about 50?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
