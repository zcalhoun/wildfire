{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a20396e",
   "metadata": {},
   "source": [
    "# In this notebook\n",
    "This notebook handles validating the results of the VAE to ensure that the reconstruction *generally* looks good.\n",
    "\n",
    "Specific model parameters analyzed:\n",
    "* Count Vector: Minimum 100 count, max 0.1 (~/wildfires/data/san_francisco/cached/min100max_01/count_vec.joblib)\n",
    "* Number of topics: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024fa437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import joblib\n",
    "sys.path.append(\"../scripts/\")\n",
    "import vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f9531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../scripts/model/model_3epoch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c35d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = joblib.load('../data/san_francisco/cached/count_vec.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19eea829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scripts/vae.py:62: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  tweets = self._load_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached file was found...loading lemmatized tweets from the cache.\n",
      "Creating the count vector\n"
     ]
    }
   ],
   "source": [
    "tweets = vae.Tweets('../data/san_francisco/')\n",
    "x_test = tweets.load(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6584e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vae.VAE(tweets.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9e3b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../scripts/model/model_3epoch.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118eb101",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_doc = x_test[0] \n",
    "recon = model(test_doc)\n",
    "s, W, mu, logvar = recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d400e7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5883e-07, 6.2493e-15, 7.7969e-16, 1.9733e-14, 1.4801e-12, 3.0517e-14,\n",
       "         1.2722e-14, 5.9346e-14, 2.1961e-16, 7.7079e-15, 2.2167e-14, 5.0431e-16,\n",
       "         2.3461e-15, 1.1333e-13, 5.6398e-15, 2.8376e-13, 3.6686e-15, 2.3433e-15,\n",
       "         2.8595e-15, 1.1051e+00]], grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd0bdacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtm = model.W_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9b374bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtm.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c242b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a394fa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "\tediting\n",
      "\tbestie\n",
      "\ttelegraph\n",
      "\telection\n",
      "\tpassive\n",
      "\tweave\n",
      "\tattendee\n",
      "\tiso\n",
      "\tblock\n",
      "\tdaughter\n",
      "\tsoul\n",
      "\ticed\n",
      "\tlaker\n",
      "\tyah\n",
      "\tcandle\n",
      "\tboarding\n",
      "\thump\n",
      "\troughly\n",
      "\tirresponsible\n",
      "\tmeal\n",
      "\n",
      "Topic 1:\n",
      "\tmurderer\n",
      "\tcruelty\n",
      "\tshed\n",
      "\tprince\n",
      "\texcel\n",
      "\tcomparable\n",
      "\tmature\n",
      "\tboy\n",
      "\tjalen\n",
      "\tokay\n",
      "\tpackaging\n",
      "\tjuicy\n",
      "\tpup\n",
      "\tfade\n",
      "\tsibling\n",
      "\tmedium\n",
      "\tbarista\n",
      "\tcanadian\n",
      "\tdebug\n",
      "\tthanks\n",
      "\n",
      "Topic 2:\n",
      "\traid\n",
      "\tharris\n",
      "\twrong\n",
      "\tignorance\n",
      "\tdiary\n",
      "\tsomewhat\n",
      "\tdramatically\n",
      "\tkkk\n",
      "\tnazis\n",
      "\tml\n",
      "\tfavorite\n",
      "\tshred\n",
      "\tdictatorship\n",
      "\tsweaty\n",
      "\tupside\n",
      "\tperfect\n",
      "\tmark\n",
      "\tmanufacturer\n",
      "\tnfl\n",
      "\tvarious\n",
      "\n",
      "Topic 3:\n",
      "\tbaseball\n",
      "\tlay\n",
      "\tshady\n",
      "\trecord\n",
      "\tclaim\n",
      "\tabsolutely\n",
      "\tmemory\n",
      "\tbiz\n",
      "\treset\n",
      "\tforeal\n",
      "\tsweep\n",
      "\tleaf\n",
      "\tdifficulty\n",
      "\tloose\n",
      "\twalgreen\n",
      "\tskull\n",
      "\treserve\n",
      "\tbarkley\n",
      "\trodger\n",
      "\tchanger\n",
      "\n",
      "Topic 4:\n",
      "\tkilling\n",
      "\thope\n",
      "\tdealer\n",
      "\ttax\n",
      "\tvicious\n",
      "\tdemocracy\n",
      "\tviking\n",
      "\tchannel\n",
      "\tunusual\n",
      "\tdray\n",
      "\tloan\n",
      "\tphoto\n",
      "\toppress\n",
      "\tfuk\n",
      "\trope\n",
      "\twound\n",
      "\tdan\n",
      "\twalgreen\n",
      "\tcashier\n",
      "\tfocus\n",
      "\n",
      "Topic 5:\n",
      "\tfil\n",
      "\thomework\n",
      "\tdoc\n",
      "\tmrs\n",
      "\tcarve\n",
      "\trhythm\n",
      "\thelicopter\n",
      "\tswoop\n",
      "\tshrug\n",
      "\tbone\n",
      "\tbreeze\n",
      "\tpacket\n",
      "\tpopularity\n",
      "\tatrocious\n",
      "\tdisrespectful\n",
      "\tliz\n",
      "\tfrank\n",
      "\tasian\n",
      "\tmi\n",
      "\tpotentially\n",
      "\n",
      "Topic 6:\n",
      "\tes\n",
      "\tsing\n",
      "\tfavs\n",
      "\tpointless\n",
      "\tleak\n",
      "\tpersonal\n",
      "\trockin\n",
      "\trisky\n",
      "\tsensible\n",
      "\tyanny\n",
      "\thennessy\n",
      "\tnetwork\n",
      "\tswimming\n",
      "\tlatin\n",
      "\toverall\n",
      "\tvictory\n",
      "\tbrain\n",
      "\tconsequence\n",
      "\ttuesday\n",
      "\tteenage\n",
      "\n",
      "Topic 7:\n",
      "\tsafety\n",
      "\tsleeve\n",
      "\tchinese\n",
      "\tdoubt\n",
      "\tfrancisco\n",
      "\taircraft\n",
      "\tgrande\n",
      "\tblessed\n",
      "\tyike\n",
      "\trodney\n",
      "\tgamble\n",
      "\tintegrity\n",
      "\tnobel\n",
      "\tlettuce\n",
      "\troberts\n",
      "\tironically\n",
      "\tviral\n",
      "\tcapable\n",
      "\trelease\n",
      "\teast\n",
      "\n",
      "Topic 8:\n",
      "\tesport\n",
      "\tnonstop\n",
      "\tjones\n",
      "\tbend\n",
      "\tfavor\n",
      "\tdisability\n",
      "\theartbreaking\n",
      "\tsixer\n",
      "\tcommission\n",
      "\thelicopter\n",
      "\tattendee\n",
      "\thorrendous\n",
      "\ttension\n",
      "\tregret\n",
      "\tew\n",
      "\tinformed\n",
      "\tskateboard\n",
      "\texcel\n",
      "\tbastard\n",
      "\tfw\n",
      "\n",
      "Topic 9:\n",
      "\ttim\n",
      "\tnowadays\n",
      "\tpatriotism\n",
      "\tlonzo\n",
      "\tct\n",
      "\tnursing\n",
      "\tanti\n",
      "\tidentity\n",
      "\tneat\n",
      "\tpronounce\n",
      "\tplacement\n",
      "\tbeast\n",
      "\treplace\n",
      "\tjoel\n",
      "\tsooooooo\n",
      "\tmilkshake\n",
      "\tdidn\n",
      "\tjesus\n",
      "\tkid\n",
      "\tcost\n",
      "\n",
      "Topic 10:\n",
      "\tsocialize\n",
      "\tconvince\n",
      "\tgenuinely\n",
      "\thometown\n",
      "\tsavage\n",
      "\tgate\n",
      "\tbaker\n",
      "\tethic\n",
      "\twage\n",
      "\tsky\n",
      "\tscarf\n",
      "\tcraft\n",
      "\tthoughtful\n",
      "\twindow\n",
      "\teasy\n",
      "\tmommy\n",
      "\tweekday\n",
      "\tcode\n",
      "\tresume\n",
      "\tpeet\n",
      "\n",
      "Topic 11:\n",
      "\tgritty\n",
      "\tgoddamn\n",
      "\tbronze\n",
      "\tcurrently\n",
      "\ttipsy\n",
      "\tsecurity\n",
      "\thail\n",
      "\ttemper\n",
      "\thalf\n",
      "\tversus\n",
      "\tfa\n",
      "\thavin\n",
      "\tprescription\n",
      "\timo\n",
      "\tmeek\n",
      "\tyike\n",
      "\twh\n",
      "\tguilt\n",
      "\tkaiser\n",
      "\tnetflix\n",
      "\n",
      "Topic 12:\n",
      "\tpsychopath\n",
      "\tmorning\n",
      "\tbooth\n",
      "\torientation\n",
      "\tstressful\n",
      "\tcabin\n",
      "\tpossess\n",
      "\toccasionally\n",
      "\tslave\n",
      "\tdrown\n",
      "\tdirection\n",
      "\tdealer\n",
      "\ttravesty\n",
      "\tsimple\n",
      "\tcrust\n",
      "\trare\n",
      "\taffect\n",
      "\tbullet\n",
      "\tfallout\n",
      "\timpeachment\n",
      "\n",
      "Topic 13:\n",
      "\ttorch\n",
      "\tsuspension\n",
      "\twoohoo\n",
      "\tdenver\n",
      "\tcustom\n",
      "\tasylum\n",
      "\tamore\n",
      "\tgum\n",
      "\texpect\n",
      "\tcart\n",
      "\tanalogy\n",
      "\tdismiss\n",
      "\thoward\n",
      "\tpray\n",
      "\talum\n",
      "\tcooperate\n",
      "\tdestroy\n",
      "\tequivalent\n",
      "\twreck\n",
      "\tdraft\n",
      "\n",
      "Topic 14:\n",
      "\tcommon\n",
      "\topenly\n",
      "\tkenny\n",
      "\taccuse\n",
      "\tbruise\n",
      "\tdebit\n",
      "\tcostco\n",
      "\tfasho\n",
      "\tgarage\n",
      "\tloss\n",
      "\tlibrary\n",
      "\tdepend\n",
      "\twendy\n",
      "\tgrandma\n",
      "\tstuff\n",
      "\tplaylist\n",
      "\tnuclear\n",
      "\tbeer\n",
      "\tcentrist\n",
      "\tpurely\n",
      "\n",
      "Topic 15:\n",
      "\tmonday\n",
      "\twoot\n",
      "\toyster\n",
      "\tgarden\n",
      "\tsafari\n",
      "\titaly\n",
      "\tunemployment\n",
      "\tipad\n",
      "\tbeautiful\n",
      "\trat\n",
      "\tap\n",
      "\tsinger\n",
      "\tadjustment\n",
      "\tinconvenience\n",
      "\tchristian\n",
      "\tweirdo\n",
      "\tmemorial\n",
      "\thint\n",
      "\tginger\n",
      "\tbarista\n",
      "\n",
      "Topic 16:\n",
      "\tequality\n",
      "\tsocialist\n",
      "\tattention\n",
      "\tbeer\n",
      "\tsalad\n",
      "\tgenerally\n",
      "\tgold\n",
      "\tcheeto\n",
      "\tmusical\n",
      "\tmature\n",
      "\tlaura\n",
      "\tdey\n",
      "\tkenny\n",
      "\tbackyard\n",
      "\thost\n",
      "\tpatriotic\n",
      "\tunderneath\n",
      "\tlgbtq\n",
      "\thilltop\n",
      "\tintel\n",
      "\n",
      "Topic 17:\n",
      "\tarrest\n",
      "\thq\n",
      "\twink\n",
      "\trly\n",
      "\tenormous\n",
      "\tcouch\n",
      "\thoward\n",
      "\tdonald\n",
      "\torg\n",
      "\tmitchell\n",
      "\tspoiler\n",
      "\tclient\n",
      "\tfarmer\n",
      "\tflee\n",
      "\tkris\n",
      "\tcruelty\n",
      "\tsociopath\n",
      "\tbarry\n",
      "\tgag\n",
      "\tmarker\n",
      "\n",
      "Topic 18:\n",
      "\treward\n",
      "\tfrisco\n",
      "\tpurse\n",
      "\tgrammar\n",
      "\tjane\n",
      "\thangover\n",
      "\tahhh\n",
      "\tiso\n",
      "\tcss\n",
      "\tsticky\n",
      "\tsunset\n",
      "\tviking\n",
      "\tnoodle\n",
      "\tinsomnia\n",
      "\tchapter\n",
      "\tcherish\n",
      "\treach\n",
      "\tadministration\n",
      "\thalftime\n",
      "\tlad\n",
      "\n",
      "Topic 19:\n",
      "\tjar\n",
      "\tcasino\n",
      "\tcleveland\n",
      "\tuv\n",
      "\tflush\n",
      "\tnomination\n",
      "\tot\n",
      "\tsalmon\n",
      "\tcomeback\n",
      "\tappalling\n",
      "\tvitamin\n",
      "\tchildhood\n",
      "\tdeclare\n",
      "\tdylan\n",
      "\tstupidity\n",
      "\tuniversity\n",
      "\tdelta\n",
      "\tsmoke\n",
      "\tlife\n",
      "\ttheatre\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_top_words(word_topic, num_words):\n",
    "    top_words = torch.argsort(word_topic, descending=True)[:, :num_words]\n",
    "    for i, topic in enumerate(top_words):\n",
    "        print(f\"Topic {i}:\")\n",
    "        print(\"\\t\"+\"\\n\\t\".join(words[topic]))\n",
    "        print()\n",
    "get_top_words(wtm, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d76e3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = x_test.dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a8bb85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.5883192e-07, 6.2492553e-15, 7.7969256e-16, 1.9733184e-14,\n",
       "       1.4801237e-12, 3.0517452e-14, 1.2721615e-14, 5.9346157e-14,\n",
       "       2.1961304e-16, 7.7078567e-15, 2.2167454e-14, 5.0431458e-16,\n",
       "       2.3461409e-15, 1.1332620e-13, 5.6398338e-15, 2.8375937e-13,\n",
       "       3.6686361e-15, 2.3433412e-15, 2.8594699e-15, 1.1051416e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.detach().numpy().flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e004f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_loadings = []\n",
    "\n",
    "for i, d in enumerate(dates):\n",
    "    \n",
    "    # Get the word vec\n",
    "    word_vec = x_test[0]\n",
    "    word_vec.requires_grad = False\n",
    "    # Pass the vector through the model\n",
    "    s, W, mu, logvar = model(word_vec)\n",
    "    \n",
    "    topic_loadings.append(s.detach().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6df2dd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 11, 12,  6,  9],\n",
       "       [ 2, 12, 18, 11, 14],\n",
       "       [ 2, 18, 11, 12,  9],\n",
       "       ...,\n",
       "       [12, 11,  2, 14, 18],\n",
       "       [ 2, 11, 12, 17, 18],\n",
       "       [ 2, 18, 11, 14,  6]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(topic_loadings, axis=1)[:,1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8da624b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-15.3875, -33.9825, -35.7263, -34.0246, -29.6566, -34.0913, -34.4844,\n",
       "         -33.0297, -37.6620, -34.4011, -31.7631, -35.4285, -34.4079, -30.0886,\n",
       "         -35.1199, -31.5863, -34.1912, -34.2304, -35.5713,  -0.1589]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ed0c59",
   "metadata": {},
   "source": [
    "Interesting...so when there are not enough topics, all of the words get lumped into one topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa569a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cough :  True\n",
      "lung :  True\n",
      "eye :  True\n",
      "itch :  True\n",
      "fire :  False\n",
      "wildfire :  True\n",
      "smoke :  True\n",
      "hurt :  True\n"
     ]
    }
   ],
   "source": [
    "# Make sure sensible words are in our corpus\n",
    "words_to_check = [\n",
    "    'cough',\n",
    "    'lung',\n",
    "    'eye',\n",
    "    'itch',\n",
    "    'fire',\n",
    "    'wildfire',\n",
    "    'smoke',\n",
    "    'hurt'\n",
    "]\n",
    "\n",
    "for w in words_to_check:\n",
    "    \n",
    "    print(w, ': ', w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4da0f913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mexican\n",
      "keeper\n",
      "jeopardy\n",
      "attack\n",
      "florida\n",
      "spanish\n",
      "dem\n",
      "cater\n",
      "mullen\n",
      "tip\n",
      "mute\n",
      "dreamforce\n",
      "sacrifice\n",
      "max\n",
      "hacker\n",
      "hitter\n",
      "specific\n",
      "lego\n",
      "module\n",
      "sibling\n",
      "contrary\n",
      "transportation\n"
     ]
    }
   ],
   "source": [
    "# What are the most probable words in this reconstruction?\n",
    "for i, v in enumerate(reversed(np.argsort(recon_vals))):\n",
    "    print(words[v])\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "abea1833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just\n",
      "good\n",
      "know\n",
      "like\n",
      "thank\n",
      "love\n",
      "make\n",
      "people\n",
      "game\n",
      "want\n",
      "say\n",
      "right\n",
      "great\n",
      "look\n",
      "today\n",
      "way\n",
      "think\n",
      "hit\n",
      "don\n",
      "work\n",
      "time\n",
      "day\n"
     ]
    }
   ],
   "source": [
    "# What are the most probable words in our generated document?\n",
    "for i, v in enumerate(reversed(np.argsort(test_doc))):\n",
    "    print(words[v])\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cd194baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japanese\n",
      "appt\n",
      "francis\n",
      "doom\n",
      "oil\n",
      "cowardly\n",
      "misogynistic\n",
      "patent\n",
      "employment\n",
      "dough\n",
      "fraud\n",
      "fit\n",
      "outing\n",
      "outfit\n",
      "wood\n",
      "quite\n",
      "omarosa\n",
      "hahaha\n",
      "rewatch\n",
      "title\n",
      "prob\n",
      "surgeon\n"
     ]
    }
   ],
   "source": [
    "# Least probable words in the reconstruction\n",
    "for i, v in enumerate(np.argsort(recon_vals)):\n",
    "    print(words[v])\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a40e96e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa\n",
      "organic\n",
      "organ\n",
      "org\n",
      "oreo\n",
      "oregon\n",
      "ordinary\n",
      "orbit\n",
      "oracle\n",
      "optional\n",
      "optimize\n",
      "optimistic\n",
      "optimism\n",
      "opt\n",
      "oppression\n",
      "oppress\n",
      "opposition\n",
      "oppose\n",
      "opportunity\n",
      "opponent\n",
      "opioid\n",
      "opinion\n"
     ]
    }
   ],
   "source": [
    "# What are the lest probable words in our generated document?\n",
    "for i, v in enumerate(np.argsort(test_doc)):\n",
    "    print(words[v])\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0a8d3a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  0.0005555555555555556\n",
      "Max:  0.1\n"
     ]
    }
   ],
   "source": [
    "# Min probability of a word being in this corpus with min_df=100\n",
    "print(\"Min: \", 1000/(1.8*10**6))\n",
    "\n",
    "# Max prob of a word being in this corpus with max_df=0.1\n",
    "print(\"Max: \", 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "46549482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90000.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.8*10**6*0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cc530103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-15.7212, -34.9691, -36.0413, -35.4208, -30.5385, -33.4864, -35.0444,\n",
       "         -33.2605, -37.6280, -35.3061, -32.4391, -37.4034, -37.1712, -30.5614,\n",
       "         -37.9732, -32.9141, -35.1267, -34.4124, -35.7661,   0.3856]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ae7cdbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2437e-06, 2.2084e-14, 3.6074e-16, 3.9704e-15, 1.1269e-12, 9.9991e-15,\n",
       "         7.4339e-16, 2.9564e-15, 3.2217e-14, 1.4587e-15, 2.1465e-15, 1.1409e-14,\n",
       "         3.5717e-15, 4.5019e-15, 7.6575e-15, 2.9934e-14, 3.7548e-16, 1.6810e-15,\n",
       "         3.8571e-15, 2.8558e-14]], grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(logvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763f835",
   "metadata": {},
   "source": [
    "## Conclusion: \n",
    "\n",
    "Looks like this specific model is probably doing OK, but some words are perhaps too infrequent or too frequent.\n",
    "\n",
    "We should look at words that only appear in at least every 20 or 50 tweets, but not more than 1000, so that they have a probability of showing up enough, but not too much.\n",
    "\n",
    "Also, it looks like we are getting negative mu's with small variances. This doesn't make sense. We need to constrain our mus to be positive, with small variances.\n",
    "\n",
    "TODO:\n",
    " - [ ] Change the count vector parameters.\n",
    " - [ ] Review the KL divergence...shouldn't these MUs be positive?\n",
    " - [ ] Add more components to the topic matrix. 20 seems too small...how about 50?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
